{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "과제어렵조",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inkyu0103/AIDetection/blob/main/%EA%B3%BC%EC%A0%9C%EC%96%B4%EB%A0%B5%EC%A1%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmiEU5uP9qsU"
      },
      "source": [
        "# 과제 많이 어렵 '조' \n",
        "\n",
        "- 조원 : **김인규 , 구다희**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E0-IXLubzsc",
        "outputId": "4853393a-0fcf-471c-abc0-db36ef65f13f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shr7s6UfcOYb"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/데이터.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvtd1-R4h5jM"
      },
      "source": [
        "# Modules install\n",
        "!pip install pefile\n",
        "!pip install numpy\n",
        "!pip install sklearn\n",
        "!pip install lightgbm\n",
        "!pip install tqdm\n",
        "!pip install pandas\n",
        "!pip install graphviz\n",
        "!pip install overload\n",
        "!pip install torch\n",
        "!pip install lief"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9lErwFTkNZN"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_extraction import FeatureHasher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE59OjSm4kyA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy7gZDaehuNU"
      },
      "source": [
        "SEED = 41\n",
        "\n",
        "def read_label_csv(path):\n",
        "    label_table = dict()\n",
        "    with open(path, \"r\",encoding='cp949') as f:\n",
        "        for line in f.readlines()[1:]:\n",
        "            fname, label = line.strip().split(\",\")\n",
        "            label_table[fname] = int(label)\n",
        "    return label_table\n",
        "\n",
        "def read_json(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def load_model(**kwargs):\n",
        "    if kwargs[\"model\"] == \"rf\":\n",
        "        return RandomForestClassifier(random_state=kwargs[\"random_state\"], n_jobs=4)\n",
        "    elif kwargs[\"model\"] == \"dt\":\n",
        "        return DecisionTreeClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lgb\":\n",
        "        return LGBMClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"svm\":\n",
        "        return SVC(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lr\":\n",
        "        return LogisticRegression(random_state=kwargs[\"random_state\"], n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"knn\":\n",
        "        return KNeighborsClassifier(n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"adaboost\":\n",
        "        return AdaBoostClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"mlp\":\n",
        "        return MLPClassifier(random_state=kwargs[\"random_state\"])\n",
        "    else:\n",
        "        print(\"Unsupported Algorithm\")\n",
        "        return None\n",
        "    \n",
        "\n",
        "def train(X_train, y_train, model):\n",
        "    clf = load_model(model=model, random_state=SEED)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def evaluate(X_test, y_test, model):\n",
        "    predict = model.predict(X_test)\n",
        "    print(\"정확도 {} \".format(model.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "# 예측 데이터로부터 정답을 뽑아내는 함수 \n",
        "def predict(x_test,model):\n",
        "  predict = model.predict(x_test)\n",
        "  print(predict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtxwfkWQhEh2"
      },
      "source": [
        "# 파일 이름\n",
        "label_table_train = read_label_csv(\"/content/학습데이터_정답.csv\")\n",
        "label_table_test = read_label_csv(\"/content/검증데이터_정답.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac54bU8e8BmA"
      },
      "source": [
        "# PEMINER\n",
        "- 새로운 특징 추가 x (188개 전부 사용)\n",
        "\n",
        "---\n",
        "\n",
        "# EMBER FEATURE\n",
        "\n",
        "### 사용한 특징\n",
        "\n",
        "\n",
        "- **histogram** --> 256차원 실수 벡터\n",
        "- **stirngs**   --> 104차원 벡터\n",
        "- **general**   --> 10차원 벡터\n",
        "- **header**    --> 10차원 벡터\n",
        "- **optional**  --> 14차원 벡터\n",
        "- ~~ section   --> 6차원 벡터 ~~ (오류 때문에 삭제)\n",
        "- **imports**   --> 1차원 벡터\n",
        "- **exports**   --> 1차원 벡터 \n",
        "- **datadirectories** --> 10차원 벡터\n",
        "\n",
        "\n",
        "### 406개의 특징 벡터\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# PESTUDIO\n",
        "\n",
        "- **overview**\n",
        "  - 모든 항목 사용\n",
        "\n",
        "- **indicators**\n",
        "  - hint \n",
        "  - xml-id\n",
        "  - detail(length)\n",
        "  - severity\n",
        "  - text (length)\n",
        "\n",
        "- **virustotal**\n",
        " - entropy\n",
        " - size\n",
        "\n",
        "- **dos-header**\n",
        " - entropy\n",
        " - size\n",
        "- **dos-stub**\n",
        " - entropy\n",
        " - size\n",
        "- **overlay**\n",
        " - entropy\n",
        " - size\n",
        "\n",
        "- **sections**\n",
        " - entropy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7rVIQYWxuc0"
      },
      "source": [
        "class PeminerParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def process_report(self):\n",
        "        self.vector = [value for _, value in sorted(self.report.items(), key=lambda x: x[0])]\n",
        "        return self.vector\n",
        "    \n",
        "\n",
        "class EmberParser:\n",
        "\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "  #------------------------------------------------------------------------------------- ㅇ 256\n",
        "    \n",
        "    def get_histogram_info(self):\n",
        "      histogram = np.array(self.report[\"histogram\"])\n",
        "      total = histogram.sum()\n",
        "      vector = histogram / total\n",
        "      \n",
        "\n",
        "      return vector.tolist()\n",
        "  \n",
        "  #------------------------------------------------------------------------------------- ㅇ 104 \n",
        "    def get_string_info(self):\n",
        "\n",
        "      strings = self.report[\"strings\"]\n",
        "      hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0\n",
        "      vector = [\n",
        "          strings['numstrings'], \n",
        "          strings['avlength'], \n",
        "          strings['printables'],\n",
        "          strings['entropy'], \n",
        "          strings['paths'], \n",
        "          strings['urls'],\n",
        "          strings['registry'], \n",
        "          strings['MZ']\n",
        "      ]\n",
        "      vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()\n",
        "      return vector\n",
        "  #------------------------------------------------------------------------------------- ㅇ 10\n",
        "    \n",
        "    def get_general_file_info(self):\n",
        "\n",
        "      try:\n",
        "        general = self.report[\"general\"]\n",
        "        vector = np.hstack([\n",
        "            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],\n",
        "            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],\n",
        "            general['symbols']\n",
        "        ]).tolist()\n",
        "\n",
        "\n",
        "      # general 속성 없는 경우 10차원 벡터 추가\n",
        "      except:\n",
        "        vector = [-1]*10\n",
        "      \n",
        "\n",
        "      \n",
        "      return vector\n",
        "  #-------------------------------------------------------------------------------------  ㅇ10\n",
        "\n",
        "    def get_header_info(self):\n",
        "      header = self.report[\"header\"][\"coff\"]\n",
        "      # string list 는 배열의 길이로 결정\n",
        "\n",
        "      self.vector=[ \n",
        "              header[\"timestamp\"], len(header[\"machine\"]),len(header[\"characteristics\"])\n",
        "      ]\n",
        "\n",
        "      return self.vector\n",
        "\n",
        "  #-------------------------------------------------------------------------------------  ㅇ 14 \n",
        "\n",
        "    def get_optional_info(self):\n",
        "      # optional이 없는 경우\n",
        "      try : \n",
        "        optional = self.report[\"optional\"]\n",
        "\n",
        "        self.vector = [ \n",
        "                  len(optional[\"subsystem\"]), len(optional[\"dll_characteristics\"]), len(optional[\"magic\"]), \n",
        "                  optional[\"major_image_version\"], optional[\"minor_image_version\"], optional[\"major_linker_version\"], optional[\"minor_linker_version\"],\n",
        "                  optional[\"major_operating_system_version\"], optional[\"minor_operating_system_version\"], optional[\"major_subsystem_version\"], optional[\"minor_subsystem_version\"], optional[\"sizeof_code\"],\n",
        "                  optional[\"sizeof_headers\"], optional[\"sizeof_heap_commit\"]\n",
        "        ]\n",
        "\n",
        "      except : \n",
        "        self.vector  = [-1]*14\n",
        "\n",
        "      return self.vector\n",
        "\n",
        "  #------------------------------------------------------------------------------------- 6 (x)\n",
        "    \n",
        "    def get_section_info(self):\n",
        "      section = self.report[\"section\"]\n",
        "      sections = section[\"sections\"]\n",
        "      vector =[\n",
        "        len(section[\"entry\"])\n",
        "      ]\n",
        "\n",
        "\n",
        "      av_name = 0\n",
        "      av_size = 0\n",
        "      av_entropy = 0\n",
        "      av_vsize = 0\n",
        "      av_props = 0 \n",
        "      \n",
        "      sec_len = len(sections)\n",
        "      if sec_len == 0 :\n",
        "        vector = [-1]*5\n",
        "\n",
        "        return vector\n",
        "\n",
        "      for i in sections :\n",
        "        av_name += len(i[\"name\"])\n",
        "        av_size += i[\"size\"]\n",
        "        av_entropy += i[\"entropy\"]\n",
        "        av_vsize += i[\"vsize\"]\n",
        "        av_props += len(i[\"props\"])\n",
        "\n",
        "      tmp_vec = [av_name/sec_len, av_size/sec_len, av_entropy/sec_len,av_vsize/sec_len, av_props/sec_len]\n",
        "      vector += tmp_vec\n",
        "\n",
        "      \n",
        "      return vector\n",
        "\n",
        "  #------------------------------------------------------------------------------------- ㅇ1\n",
        "\n",
        "    def get_imports_info(self):\n",
        "      '''\n",
        "        imports 부분이 dictionary라 몇 개가 들어올지 모르기 때문에, key의 개수로 하도록 할게요\n",
        "        그리고 키 값도 다를 수 있으니... key만 뽑아서 할 것.\n",
        "\n",
        "      '''\n",
        "\n",
        "      imports = self.report[\"imports\"]\n",
        "      import_key_list = len(imports.keys())\n",
        "      \n",
        "      \n",
        "      vector = [import_key_list]\n",
        "      return vector\n",
        "\n",
        "  #------------------------------------------------------------------------------------- ㅇ 1\n",
        "    \n",
        "    def get_exports_info(self):\n",
        "      '''\n",
        "      export부분의 원소가 어떤 type인지 모르기 때문에, export도 len으로 맞춰주었습니다.\n",
        "\n",
        "      만약 string으로 고정된다면, string length의 평균을 기준으로 해보려고 했어요.\n",
        "      '''\n",
        "\n",
        "      exports = self.report[\"exports\"]\n",
        "      vector = [len(exports)]\n",
        "\n",
        "      return vector\n",
        "\n",
        "  #-------------------------------------------------------------------------------------\n",
        "  \n",
        "    def get_datadirectories_info(self):\n",
        "      vector = []\n",
        "      '''\n",
        "        name , size , virtual_addr 이 세부분으로 이루어져 있으니 평균을 내어 구합니다.\n",
        "      '''\n",
        "      datadirectories = self.report[\"datadirectories\"]\n",
        "      \n",
        "      av_name = 0\n",
        "      av_size = 0 \n",
        "      av_virtual_addr = 0 \n",
        "\n",
        "      length = len(datadirectories)\n",
        "      \n",
        "      if length == 0 :\n",
        "        vector =[-1]*3\n",
        "        return vector\n",
        "      \n",
        "      for i in datadirectories:\n",
        "        av_name += len(i[\"name\"])\n",
        "        av_size += i[\"size\"]\n",
        "        av_virtual_addr += i[\"virtual_address\"]\n",
        "\n",
        "      tmp_vec = [av_name/length , av_size / length, av_virtual_addr/length]\n",
        "\n",
        "      vector += tmp_vec\n",
        "      return vector\n",
        "  #-------------------------------------------------------------------------------------\n",
        "\n",
        "    def process_report(self):\n",
        "      vector = []\n",
        "      vector += self.get_histogram_info()  # O\n",
        "      vector += self.get_string_info() # O\n",
        "      vector += self.get_general_file_info() # O\n",
        "      vector += self.get_header_info() # O\n",
        "      vector += self.get_optional_info() # ㅇ\n",
        "      #vector += self.get_section_info()  x      \n",
        "      vector += self.get_optional_info() # ㅇ\n",
        "      vector += self.get_imports_info() # ㅇ\n",
        "      vector += self.get_exports_info() # ㅇ\n",
        "      vector += self.get_datadirectories_info() # ㅇ  \n",
        "\n",
        "      return vector\n",
        "\n",
        "\n",
        "############################################################################################\n",
        "\n",
        "class PestudioParser:        \n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "  #------------------------------------------------------------------------------------- 25\n",
        "\n",
        "    def get_overview_info (self):\n",
        "      \n",
        "      v = []\n",
        "      overview = self.report[\"image\"][\"overview\"]\n",
        "\n",
        "      #overview key list\n",
        "      overview_key_list = list(self.report[\"image\"][\"overview\"].keys())\n",
        "\n",
        "      int_candidate = [\"cpu\",\"size\",\"size-without-overlay\",\"entropy\"]\n",
        "      for item in overview_key_list : \n",
        "        if item in int_candidate:\n",
        "          if overview[item] != \"n/a\":\n",
        "            v.append(float(overview[item]))\n",
        "          else:\n",
        "            v.append(-1)\n",
        "        else:\n",
        "          if overview[item] == None:\n",
        "            v.append(-1)\n",
        "          elif len(overview[item]) >3 :\n",
        "            v.append(len(overview[item]))\n",
        "          else:\n",
        "            v.append(-1)\n",
        "      \n",
        "      return v\n",
        "          \n",
        "  #------------------------------------------------------------------------------------- 5차원\n",
        "    \n",
        "    def get_indicators_info (self):\n",
        "      vector = []\n",
        "      indicators = self.report[\"image\"][\"indicators\"]\n",
        "      # hint\n",
        "      vector.append(len(indicators[\"@hint\"])) if len(indicators[\"@hint\"]) > 3 else vector.append(-1)\n",
        "    \n",
        "      #indicator (indicator가 없는 파일도 존재)\n",
        "      try : \n",
        "        indicator = indicators[\"indicator\"]\n",
        "\n",
        "        l = len(indicator)\n",
        "        av_xml = 0\n",
        "        av_detail = 0  # (length로)\n",
        "        av_severity = 0\n",
        "        av_text = 0 #(length로)\n",
        "\n",
        "      \n",
        "        for i in indicator:\n",
        "          av_xml += int(i[\"@xml-id\"])\n",
        "          av_detail = len(i[\"@detail\"])\n",
        "          av_severity = int(i[\"@severity\"])\n",
        "          av_text = len(i[\"#text\"])\n",
        "\n",
        "        if l != 0 :\n",
        "          vector.append(av_xml/l)\n",
        "          vector.append(av_detail/l)\n",
        "          vector.append(av_severity/l)\n",
        "          vector.append(av_text/l)\n",
        "\n",
        "        if l == 0:\n",
        "          vector += [-1,-1,-1,-1]\n",
        "\n",
        "\n",
        "      except : \n",
        "        #indicator가 없는 경우\n",
        "        vector += [-1,-1,-1,-1]\n",
        "\n",
        "      return vector\n",
        "\n",
        "        \n",
        "  #------------------------------------------------------------------------------------- 2차원\n",
        "\n",
        "    # 유무로 판단\n",
        "    def get_virustotal_info(self):\n",
        "      try:\n",
        "        vector = []\n",
        "        virustotal = self.report[\"image\"][\"virustotal\"]\n",
        "\n",
        "\n",
        "        detection = virustotal[\"@detection\"]\n",
        "        engine = virustotal[\"@engine\"]\n",
        "\n",
        "        vector += int(detection)\n",
        "        vector += int(engine)\n",
        "\n",
        "      except:\n",
        "        vector +=[-1,-1]\n",
        "\n",
        "      return vector\n",
        "\n",
        "  #------------------------------------------------------------------------------------- 2차원\n",
        "\n",
        "    def get_dos_header_info(self):\n",
        "      vector = []\n",
        "      try:\n",
        "        dos_header = self.report[\"image\"][\"dos-header\"]\n",
        "\n",
        "      except:\n",
        "        vector += [-1,-1]\n",
        "        return vector\n",
        "      \n",
        "      try:\n",
        "        entropy = dos_header[\"entropy\"]\n",
        "        vector.append(int(entropy))\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "      try:\n",
        "        size = dos_header[\"size\"]\n",
        "        vector.append(int(size))\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "\n",
        "      \n",
        "\n",
        "      return vector\n",
        "\n",
        "\n",
        "\n",
        "  #------------------------------------------------------------------------------------- 2차원 \n",
        "    def get_dos_stub_info(self):\n",
        "      vector = []\n",
        "      try:\n",
        "        dos_stub = self.report[\"image\"][\"dos-stub\"]\n",
        "      except:\n",
        "        vector += [-1,-1]\n",
        "        return vector\n",
        "      try:\n",
        "        entropy = dos_stub[\"entropy\"]\n",
        "        vector.append(int(entropy))\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "      try:\n",
        "        size = dos_stub[\"size\"]\n",
        "        vector.append(int(size))\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "\n",
        "      return vector\n",
        "        \n",
        "    #------------------------------------------------------------------------------------- 1차원 \n",
        "\n",
        "    def get_sections_info(self):\n",
        "      vector =[]\n",
        "      try:\n",
        "        sections = self.report[\"image\"][\"sections\"]\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "        return vector\n",
        "\n",
        "      try:\n",
        "        av_entropy = 0\n",
        "        section = sections[\"section\"]\n",
        "        for i in section:\n",
        "          av_entropy += float(i[\"@entropy\"])\n",
        "        \n",
        "        vector.append(av_entropy/len(section))\n",
        "\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "\n",
        "      return vector\n",
        "\n",
        "\n",
        "    #------------------------------------------------------------------------------------- 2차원 \n",
        "\n",
        "    def get_overlay_info(self):\n",
        "      vector = []\n",
        "      try:\n",
        "        overlay = self.report[\"image\"][\"overlay\"]\n",
        "      except:\n",
        "        vector += [-1,-1]\n",
        "        return vector\n",
        "\n",
        "      try : \n",
        "        entropy = float(overlay[\"entropy\"])\n",
        "        vector.append(entropy)\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "      \n",
        "      try:\n",
        "        size = float(overlay[\"size\"])\n",
        "        vector.append(size)\n",
        "\n",
        "      except:\n",
        "        vector.append(-1)\n",
        "\n",
        "      return vector\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------\n",
        "    \n",
        "    def process_report(self):\n",
        "      vector = [] \n",
        "      vector += self.get_overview_info()  #\n",
        "      vector += self.get_indicators_info() #\n",
        "      vector += self.get_virustotal_info() #\n",
        "      vector += self.get_dos_header_info() #\n",
        "      vector += self.get_dos_stub_info() #\n",
        "      vector += self.get_sections_info() #\n",
        "      vector += self.get_overlay_info() #\n",
        "\n",
        "\n",
        "      return vector\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo8XybYQJaR6",
        "outputId": "0c7b6372-8ebb-41de-cdf3-8869abb5791e"
      },
      "source": [
        "pestudio_test_file =  []\n",
        "\n",
        "# pestudio_test_file (.json 빠진 파일 이름만 있는 리스트)\n",
        "for i in  glob.glob(\"/content/PESTUDIO/테스트데이터/*.json\"):\n",
        "  pestudio_test_file.append(os.path.basename(i).split(\".\")[0])\n",
        "\n",
        "\n",
        "\n",
        "other_test_file = []\n",
        "# other_test_file (.json 빠진 파일 이름만 있는 리스트)\n",
        "for i in  glob.glob(\"/content/PEMINER/테스트데이터/*.json\"):\n",
        "  other_test_file.append(os.path.basename(i).split(\".\")[0])\n",
        "\n",
        "\n",
        "real_test_file = list(set(pestudio_test_file).intersection(other_test_file))\n",
        "\n",
        "print(len(real_test_file))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G12bZbNQj8PZ"
      },
      "source": [
        "\n",
        "###################### TRAIN DATA ####################\n",
        "# fname_list =>  모든 학습 파일이름(확장자 제외) \n",
        "fname_train_list = list(label_table_train)\n",
        "\n",
        "\n",
        "# PESTUDIO TRAIN DATA\n",
        "pestudio_train_list=[]\n",
        "for path in glob.glob(\"/content/PESTUDIO/학습데이터/*.json\"):\n",
        "  pestudio_train_list.append(os.path.basename(path).split(\".\")[0])\n",
        "\n",
        "#real_train_list : 겹치는 파일 (19940 개)\n",
        "real_train_list = list(set(fname_train_list).intersection(pestudio_train_list))\n",
        "\n",
        "\n",
        "###################### VALIDATION DATA ####################\n",
        "\n",
        "# fname_list (.json 빠진 파일 이름만 있는 리스트)\n",
        "fname_validate_list = list(label_table_test)\n",
        "\n",
        "# PESTUDIO VALIDATION DATA\n",
        "pestudio_validate_list=[]\n",
        "for path in glob.glob(\"/content/PESTUDIO/검증데이터/*.json\"):\n",
        "  pestudio_validate_list.append(os.path.basename(path).split(\".\")[0])\n",
        "\n",
        "#real_validate_list : 겹치는 파일 (9798 개)\n",
        "real_validate_list = list(set(fname_validate_list).intersection(pestudio_validate_list))\n",
        "\n",
        "\n",
        "###################### TEST DATA ####################\n",
        "\n",
        "\n",
        "pestudio_test_file =  []\n",
        "\n",
        "# pestudio_test_file (.json 빠진 파일 이름만 있는 리스트)\n",
        "for i in  glob.glob(\"/content/PESTUDIO/테스트데이터/*.json\"):\n",
        "  pestudio_test_file.append(os.path.basename(i).split(\".\")[0])\n",
        "\n",
        "\n",
        "\n",
        "other_test_file = []\n",
        "# other_test_file (.json 빠진 파일 이름만 있는 리스트)\n",
        "for i in  glob.glob(\"/content/PEMINER/테스트데이터/*.json\"):\n",
        "  other_test_file.append(os.path.basename(i).split(\".\")[0])\n",
        "\n",
        "\n",
        "#9809 개 \n",
        "real_test_file = list(set(pestudio_test_file).intersection(other_test_file))\n",
        "\n",
        "\n",
        "################### TEST DATA2  (나머지) #######################\n",
        "\n",
        "resi_test_file = list(set(other_test_file)- set(pestudio_test_file))\n",
        "\n",
        "\n",
        "\n",
        "# 188 / 406 / 39\n",
        "\n",
        "\n",
        "\n",
        "# x_train : 훈련집합 특징 벡터\n",
        "# y_train : 훈련집합 정답\n",
        "tr = 0\n",
        "x_train, y_train = [], []\n",
        "for fname in fname_train_list:  \n",
        "  print(\"tr {} \".format(tr))\n",
        "  feature_vector = []\n",
        "  # label_table --> dictionary { file_name : answer }\n",
        "  label = label_table_train[fname] \n",
        "\n",
        "  for data in [\"PEMINER\",\"EMBER\",\"PESTUDIO\"]:\n",
        "      path = f\"/content/{data}/학습데이터/{fname}.json\"\n",
        "      if data == \"PESTUDIO\" and fname in real_train_list:\n",
        "        feature_vector += PestudioParser(path).process_report()\n",
        "      elif data ==\"PESTUDIO\":\n",
        "        feature_vector += = [-1]*39\n",
        "      elif data == \"PEMINER\":\n",
        "        feature_vector += PeminerParser(path).process_report()\n",
        "      elif data ==\"EMBER\":\n",
        "        feature_vector += EmberParser(path).process_report()\n",
        "  x_train.append(feature_vector)\n",
        "  y_train.append(label)\n",
        "  tr += 1\n",
        "\n",
        "print(\"next\")\n",
        "\n",
        "x_val,y_val = [],[]\n",
        "va = 0\n",
        "# 테스트 집합 파일 리스트 ()\n",
        "fname_list = list(label_table_test)\n",
        "\n",
        "# pestudio 테스트 집합 이름 (루트~  파일명)\n",
        "pestudio_test_list = glob.glob(\"/content/PESTUDIO/검증데이터/*.json\")\n",
        "\n",
        "\n",
        "for fname in fname_validate_list:\n",
        "  print(\"검증 data {}\".format(va))\n",
        "\n",
        "  feature_vector = []\n",
        "  label = label_table_test[fname]\n",
        "  for data in [\"PEMINER\",\"EMBER\",\"PESTUDIO\"]:\n",
        "    path = f\"/content/{data}/검증데이터/{fname}.json\"\n",
        "    if data == \"PESTUDIO\" and real_validate_list:\n",
        "      feature_vector += PestudioParser(path).process_report()      \n",
        "    elif data ==\"PESTUDIO\":\n",
        "      feature_vector += [-1]*39\n",
        "    elif data == \"PEMINER\":\n",
        "      feature_vector += PeminerParser(path).process_report()\n",
        "      \n",
        "    elif data == \"EMBER\":\n",
        "      feature_vector += EmberParser(path).process_report()\n",
        "      \n",
        "  x_val.append(feature_vector)\n",
        "  y_val.append(label)\n",
        "  va+=1\n",
        "\n",
        "\n",
        "x_test,y_test= [],[]\n",
        "t  = 0 \n",
        "for fname in other_test_file:\n",
        "  print(\"test data {}\".format(t))\n",
        "  feature_vector = []\n",
        "  for data in [\"PEMINER\",\"EMBER\",\"PESTUDIO\"]:\n",
        "      path = f\"/content/{data}/테스트데이터/{fname}.json\"\n",
        "\n",
        "      if data == \"PESTUDIO\" and fname in real_test_file:\n",
        "        feature_vector += PestudioParser(path).process_report()\n",
        "\n",
        "      elif data == \"PESTUDIO\": \n",
        "        feature_vector += [-1]*39      \n",
        "\n",
        "      elif data == \"PEMINER\":\n",
        "        feature_vector += PeminerParser(path).process_report()\n",
        "        \n",
        "      elif data == \"EMBER\":\n",
        "        feature_vector += EmberParser(path).process_report()\n",
        "\n",
        "  x_test.append(feature_vector)\n",
        "  t+=1\n",
        "\n",
        "  #633개 특징\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdRpgktRJd8u",
        "outputId": "9a029a3f-65dd-42c4-fd29-006065d83171"
      },
      "source": [
        "# 학습\n",
        "models = []\n",
        "for model in [\"rf\", \"lgb\"]:\n",
        "    clf = train(x_train, y_train, model)\n",
        "    models.append(clf)\n",
        "\n",
        "# 검증\n",
        "\n",
        "for model in models:\n",
        "    evaluate(x_val, y_val, model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9454990814451929 \n",
            "정확도 0.9526433966115534 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLPf3VPanm2c"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSJek8CUpd3K"
      },
      "source": [
        "def ensemble_result(X, y, models):\n",
        "    predicts = []\n",
        "    for model in models:\n",
        "        prob = [result for _, result in model.predict_proba(X)]\n",
        "        predicts.append(prob)\n",
        "    \n",
        "    predict = np.mean(predicts, axis=0)\n",
        "    predict = [1 if x >= 0.5 else 0 for x in predict]\n",
        "    \n",
        "    print(\"정확도\", accuracy_score(y, predict))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    학습과정에서 pestudio에 없는 파일은 학습시키지 않았을 때, rf : 0.9455 ... / lgb : 0.9526 / 앙상블 : 0.9539 ... \n",
        "\n",
        "\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4GiCVcmWopp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b22d388-7d37-4934-f9e8-06ab11a3d89f"
      },
      "source": [
        "ensemble_result(x_val,y_val,models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.9538681363543581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvZOm5d8zrIm"
      },
      "source": [
        "def predict(x_test,models):\n",
        "  for model in models:\n",
        "    predict = model.predict(x_test)\n",
        "  return predict \n",
        "\n",
        "# 테스트 데이터에 대한 예측 값\n",
        "predict_result = predict(x_test,models)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrjX108Jpuyi"
      },
      "source": [
        "# csv 파일 쓰기\n",
        "\n",
        "import csv\n",
        "\n",
        "data_list = []\n",
        "f = open('predict.csv','w')\n",
        "csv_writer = csv.writer(f)\n",
        "csv_writer.writerow(['file','predict'])\n",
        "for i in range(10000):\n",
        "  csv_writer.writerow([other_test_file[i],predict_result[i]])\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}